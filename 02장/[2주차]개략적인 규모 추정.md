> 발표자:  신예진

## 요약
- 개략적인 규모 추정
*** 

## 개략적인 규모 추정 
👉🏻 보편적으로 통용되는 성능 수치사에서 사고 실험을 행하여 추정치를 계산하는 행위로서, 어떤 설계가 요구사항에 부합할 것인지 보기 위한 것.
* 개략적으로 규모 추정을 효과적으로 해 내려면 규모 확장성을 표현할 수 있어야 한다.

## 2의 제곱수 
* 데이터 볼륨의 단위를 2의 제곱수로 표현하면 어떻게 되는지 알아야 함.
* 최소 단위 : 1byte / 8 bit (ASCII문자 하나가 차지하는 메모리 크기가 1byte)

| 2의 x제곱 (바이트)                   | 근사치(10진 바이트)      | 이름    | 축약형 |
| ------------------------------ | ----------------- | ----- | --- |
| 2^0 (1 B)                      | 1 B               | 바이트   | B   |
| 2^10 (1,024 B)                 | ≈ 1.024 × 10^3 B  | 킬로바이트 | KB  |
| 2^20 (1,048,576 B)             | ≈ 1.049 × 10^6 B  | 메가바이트 | MB  |
| 2^30 (1,073,741,824 B)         | ≈ 1.074 × 10^9 B  | 기가바이트 | GB  |
| 2^40 (1,099,511,627,776 B)     | ≈ 1.100 × 10^12 B | 테라바이트 | TB  |
| 2^50 (1,125,899,906,842,624 B) | ≈ 1.126 × 10^15 B | 페타바이트 | PB  |


## 프로그래머가 알아야 하는 응답지연 값 
| 항목                             | 시간            | 백엔드 개발 시 왜 중요한가?                                               |
| ------------------------------ | ------------- | -------------------------------------------------------------- |
| **메모리 참조 (L1/L2 캐시, DRAM 접근)** | 수 ns \~ 수백 ns | 코드 최적화보다는 **데이터 구조 설계** 시 고려. CPU 캐시 미스가 자주 나면 성능 급락.          |
| **1 Gbps 네트워크로 2 KB 전송**       | ≈ 20µs        | 작은 패킷 전송은 빠르지만, 응답 지연(latency)은 무시 못 함. 마이크로서비스 간 통신 비용 이해 필요. |
| **메모리에서 1 MB 순차적 read**        | ≈ 250µs       | 대용량 데이터 처리 시 메모리 접근은 빠른 편이라 DB hit보다 훨씬 유리. 캐싱 전략과 관련.         |
| **같은 데이터센터 내 메시지 왕복 지연**       | ≈ 500µs       | 마이크로서비스, Redis, Kafka 같은 **네트워크 통신 오버헤드** 체감에 필요.              |
| **디스크 탐색(seek)**               | ≈ 10ms        | HDD일 때의 디스크 I/O 속도. 아직도 일부 시스템 로그/백업에서 중요. SSD에서는 훨씬 줄어듦.      |
| **네트워크에서 1 MB 순차적 read**       | ≈ 10ms        | 원격 호출(API, 외부 DB, 파일 서버) 속도 감 잡기. 캐시 필요성 판단 근거.                |
| **디스크에서 1 MB 순차적 read**        | ≈ 30ms        | DB에서 인덱스 없이 큰 데이터 읽을 때 체감되는 비용.                                |
| **대륙 간 네트워크 왕복 (CA↔네덜란드)**     | ≈ 150ms       | 해외 API 호출, 클라우드 리전 간 통신 시 반드시 고려해야 하는 **네트워크 지연 한계**.          |

### 캐시/메모리/네트워크/디스크/지연(latency)의 상대적인 규모
* 메모리 < 네트워크(데이터센터 내부) < 디스크 < 해외 네트워크 순서로 느려짐.
* "DB Hit 한 번" vs "메모리 캐시 Hit"의 차이가 수백~수천 배 이상
=> 이걸 알면 캐싱 전략, DB 설계, 마이크로서비스 통신 구조를 짤 때 왜 성능 차이가 나는지 바로 이해할 수 있다.

* 메모리는 빠르지만 디스크는 아직도 느리다.
* 디스크 탐색(seek)은 가능한 한 피하라.
* 단순한 압축 알고리즘은 빠르다.
  > 🔹 대표적인 단순 압축 알고리즘
  > * 런-랭스 인코딩 (Run-Length Encoding, RLE)
  >   연속된 같은 문자를 문자 + 반복 횟수로 표현하는 방식
  >   예: AAAAABBBCC → A5B3C2
  >   이미지(특히 흑백 이미지)나 로그 같은 반복이 많은 데이터에서 유용
  >  단점: 데이터가 다양하게 섞여 있으면 오히려 커질 수 있음
  > * 허프만 코딩 (Huffman Coding)
  >   자주 등장하는 문자는 짧은 코드, 드물게 등장하는 문자는 긴 코드로 표현하는 방식
  >   텍스트 압축의 기초 원리 중 하나
  >   ZIP, JPEG 등 많은 압축 포맷에서 사용됨
  > * 고정 길이 vs 가변 길이 인코딩
  >   예: ASCII는 고정 길이(8비트), 하지만 문자 빈도에 따라 가변 길이 코드를 주면 압축 효과
  >   대표 예시가 바로 허프만 코딩
  > * 간단한 사전 기반 치환 (LZ77, LZ78 초기 형태
  >   중복된 문자열을 "이전에 나온 위치와 길이"로 치환하는 방식
  >   예: ABCABCABC → (ABC)x3 식으로 표현 가능
  >   ZIP, PNG 등 실무 압축 알고리즘의 기초

## 가용성에 관계된 수치들 
* 고가용성(high availability)은 시스템이 오랜 시간 동안 지속적으로 중단 없이 운영될 수 있는 능력을 지칭하는 용어.
* 100% => 시스템이 단 한번도 중단된 적이 없었음을 의미
* 대부분의 서비스는 99%에서 100%사이의 값을 갖는다.
* 아마존, 구글, 마이크로소프트 같은 사업자는 99%이상의 SLA(Service Level Agreement)제공. 


*** 
+ 각 회사의 개선점 공유 & 해결방안 함께 고민
